{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f138c4c5",
   "metadata": {},
   "source": [
    "# PREDICTING EMPLOYEE BURNOUT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac1b1f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "### importing libraries \n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5edec1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\brij bhushan singla\\anaconda3\\lib\\site-packages (0.11.1)\n",
      "Requirement already satisfied: pandas>=0.23 in c:\\users\\brij bhushan singla\\anaconda3\\lib\\site-packages (from seaborn) (1.2.4)\n",
      "Requirement already satisfied: matplotlib>=2.2 in c:\\users\\brij bhushan singla\\anaconda3\\lib\\site-packages (from seaborn) (3.3.4)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\brij bhushan singla\\anaconda3\\lib\\site-packages (from seaborn) (1.6.2)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\brij bhushan singla\\anaconda3\\lib\\site-packages (from seaborn) (1.20.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\brij bhushan singla\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\brij bhushan singla\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\brij bhushan singla\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\brij bhushan singla\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\brij bhushan singla\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (8.2.0)\n",
      "Requirement already satisfied: six in c:\\users\\brij bhushan singla\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib>=2.2->seaborn) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\brij bhushan singla\\anaconda3\\lib\\site-packages (from pandas>=0.23->seaborn) (2021.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6e15eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311f6e95",
   "metadata": {},
   "source": [
    "# Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53adaebe",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-1ed46c1cea02>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mTrain_Data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train.csv'"
     ]
    }
   ],
   "source": [
    "Train_Data=pd.read_csv('.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987579ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Data=pd.read_csv('Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c111579b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sample_Data=pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e7b27d",
   "metadata": {},
   "source": [
    "##  EXPLORATION AND VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916a8a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (Train_Data.shape)\n",
    "Train_Data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cead85",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71babef",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4626c319",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050c3111",
   "metadata": {},
   "outputs": [],
   "source": [
    "### BURN RATE V/S GENDER \n",
    "Train_Data[['Gender', 'Burn Rate']].groupby('Gender').agg('mean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370a1d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Data.boxplot(column=['Burn Rate'], by='Gender')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6cd4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### thus gender affects burn rate but not much "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc21a124",
   "metadata": {},
   "outputs": [],
   "source": [
    "### BURN RATE V/S WFH AVAILABILITY\n",
    "Train_Data[['WFH Setup Available', 'Burn Rate']].groupby('WFH Setup Available').agg('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546ff04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### high corr between wfh setub availability and burn rate \n",
    "Train_Data.boxplot(column=['Burn Rate'],by='WFH Setup Available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eeb42c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### BURN RATE V/S COMPANY TYPE \n",
    "Train_Data[['Company Type', 'Burn Rate']].groupby('Company Type').agg('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33787846",
   "metadata": {},
   "outputs": [],
   "source": [
    "### company type does not really affect burn rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b593715",
   "metadata": {},
   "outputs": [],
   "source": [
    "### BURN RATE V/S DESIGNATION \n",
    "Train_Data[['Designation','Burn Rate']].groupby('Designation').agg('mean')\n",
    "### relation is almost linear "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8215877a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Data.boxplot(column=['Burn Rate'], by='Designation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a1f490",
   "metadata": {},
   "outputs": [],
   "source": [
    "### burn rate vs resource allocation i.e no of working hours \n",
    "Train_Data[['Resource Allocation','Burn Rate']].groupby('Resource Allocation').agg('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29993297",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Data.boxplot(column=['Burn Rate'], by='Resource Allocation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5521e823",
   "metadata": {},
   "outputs": [],
   "source": [
    "### BURN RATE V/S MENTAL FATIGUE \n",
    "Train_Data[['Mental Fatigue Score','Burn Rate']].groupby('Mental Fatigue Score').agg('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02516e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Data.boxplot(column=['Burn Rate'], by='Mental Fatigue Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92e8f8a",
   "metadata": {},
   "source": [
    "### CORRELATION  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93692392",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "heatmap = sns.heatmap(Train_Data.corr(), vmin=-1, vmax=1, annot=True)\n",
    "heatmap.set_title('Correlation Heatmap', fontdict={'fontsize':15}, pad=12);\n",
    "plt.savefig(\"correlation_heatmap.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dbc658",
   "metadata": {},
   "source": [
    "##   DATA CLEANING  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdc3f34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## remove burn rate null values by droping the entries\n",
    "Train_Data.dropna(subset = [\"Burn Rate\",'Resource Allocation','Mental Fatigue Score'], inplace=True)\n",
    "Train_Data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5422424f",
   "metadata": {},
   "source": [
    "## DATA LABELLING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4fa612",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_encoder(data):\n",
    "    if data[\"Gender\"] == \"Female\":\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "def wfh_setup_encoder(data):\n",
    "    if data[\"WFH Setup Available\"] == \"Yes\":\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "def company_encoder(data):\n",
    "    if data[\"Company Type\"] == \"Service\":\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "\n",
    "Train_Data[\"Gender\"] = Train_Data.apply(gender_encoder, axis=1)\n",
    "Train_Data[\"WFH Setup Available\"] = Train_Data.apply(wfh_setup_encoder, axis=1)\n",
    "Train_Data[\"Company Type\"] = Train_Data.apply(company_encoder, axis=1)\n",
    "\n",
    "Test_Data[\"Gender\"] = Test_Data.apply(gender_encoder, axis=1)\n",
    "Test_Data[\"WFH Setup Available\"] = Test_Data.apply(wfh_setup_encoder, axis=1)\n",
    "Test_Data[\"Company Type\"] = Test_Data.apply(company_encoder, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6433f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Data.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0deb165",
   "metadata": {},
   "source": [
    "### CATEGORISING DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e496bedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### categorizing mental fatigue levels , designation and resource allocation \n",
    "def categorize_Mental_Fatigue(data):\n",
    "    if data[\"Mental Fatigue Score\"] <= 4.0:\n",
    "        return 0\n",
    "    if data[\"Mental Fatigue Score\"] > 4.0 and data[\"Mental Fatigue Score\"] <= 5.0:\n",
    "        return 1\n",
    "    if data[\"Mental Fatigue Score\"] > 5.0 and data[\"Mental Fatigue Score\"] <= 6.0:\n",
    "        return 2\n",
    "    if data[\"Mental Fatigue Score\"] > 6.0 and data[\"Mental Fatigue Score\"] <= 7.0:\n",
    "        return 3\n",
    "    if data[\"Mental Fatigue Score\"] > 7.0:\n",
    "        return 4\n",
    "    return -1\n",
    "\n",
    "def categorize_designation(data):\n",
    "    if data[\"Designation\"] <= 1.0:\n",
    "        return 0\n",
    "    if data[\"Designation\"] > 1.0 and data[\"Designation\"] <= 3.0:\n",
    "        return 1\n",
    "    if data[\"Designation\"] > 3.0 and data[\"Designation\"] <= 5.0:\n",
    "        return 2\n",
    "    return -1\n",
    "\n",
    "\n",
    "def categorize_resource(data):\n",
    "    if data[\"Resource Allocation\"] <= 3.0:\n",
    "        return 0\n",
    "    if data[\"Resource Allocation\"] > 3.0 and data[\"Resource Allocation\"] <= 6.0:\n",
    "        return 1\n",
    "    if data[\"Resource Allocation\"] > 6.0 and data[\"Resource Allocation\"] <= 10.0:\n",
    "        return 2\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7623306",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Data[\"Categorize Mental Fatigue\"] = Train_Data.apply(categorize_Mental_Fatigue, axis=1)\n",
    "Test_Data[\"Categorize Mental Fatigue\"] = Test_Data.apply(categorize_Mental_Fatigue, axis=1)\n",
    "\n",
    "Train_Data[\"Categorize Designation\"] = Train_Data.apply(categorize_designation, axis=1)\n",
    "Test_Data[\"Categorize Designation\"] = Test_Data.apply(categorize_designation, axis=1)\n",
    "\n",
    "Train_Data[\"Categorize Resource Allocation\"] = Train_Data.apply(categorize_resource, axis=1)\n",
    "Test_Data[\"Categorize Resource Allocation\"] = Test_Data.apply(categorize_resource, axis=1)\n",
    "Train_Data.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fd4756",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONVERTING COLUMN DATE OF JOINING TO MORE USEFULT DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d286e5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Date_Today = pd.to_datetime('today')\n",
    "\n",
    "Train_Data[\"Date of Joining\"] = pd.to_datetime(Train_Data[\"Date of Joining\"])\n",
    "Test_Data[\"Date of Joining\"] = pd.to_datetime(Test_Data[\"Date of Joining\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d66090",
   "metadata": {},
   "outputs": [],
   "source": [
    "### create a func to calc no. of working days of employee since joining the company \n",
    "def create_days_count(data):\n",
    "    return (Date_Today - data[\"Date of Joining\"])\n",
    "\n",
    "Train_Data[\"days_count\"] = Train_Data.apply(create_days_count, axis=1)\n",
    "Train_Data[\"days_count\"] = Train_Data[\"days_count\"].dt.days\n",
    "\n",
    "Test_Data[\"days_count\"] = Test_Data.apply(create_days_count, axis=1)\n",
    "Test_Data[\"days_count\"] = Test_Data[\"days_count\"].dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470e7df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c518bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Data.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d96df0e",
   "metadata": {},
   "source": [
    "### NORMALISING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b93670",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_cols = [\"Designation\", \"Resource Allocation\", \"Mental Fatigue Score\"]\n",
    "#              + [\"days_count\", \"categorize_designation\", \"categorize_resource\", \"categorize_Mental_Fatigue\"]\n",
    "\n",
    "train_data_min = Train_Data[norm_cols].min()\n",
    "train_data_max = Train_Data[norm_cols].max()\n",
    "\n",
    "Train_Data[norm_cols] = (Train_Data[norm_cols] - train_data_min)/(train_data_max - train_data_min)\n",
    "Test_Data[norm_cols] = (Test_Data[norm_cols] - train_data_min)/(train_data_max - train_data_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2f62fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### drop useless columns\n",
    "Train_Data.drop(['Date of Joining', \"Employee ID\"], axis=1, inplace=True)\n",
    "Test_Data.drop(['Date of Joining', \"Employee ID\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0176b64",
   "metadata": {},
   "source": [
    "## SAVING CLEAN DATA  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5bf458",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = Train_Data.copy()\n",
    "\n",
    "Train_Data.to_csv(\"clean_df_train.csv\", index=False)\n",
    "train_file_path = \"./clean_df_train.csv\"\n",
    "Clean_Train = pd.read_csv(train_file_path)\n",
    "\n",
    "Test_Data.to_csv(\"clean_df_test.csv\", index=False)\n",
    "test_file_path = \"./clean_df_test.csv\"\n",
    "Clean_Test = pd.read_csv(test_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1407aac9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Clean_Train.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439c4ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Clean_Test.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e837074",
   "metadata": {},
   "source": [
    "##  SPLITTING DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55695191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nitzan try\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lr = LabelEncoder()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "X=Clean_Train.drop(['Burn Rate'],axis=1)\n",
    "Clean_Train['Burn Rate']=LabelEncoder().fit_transform(Clean_Train['Burn Rate'])\n",
    "y = Clean_Train['Burn Rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed86285",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "#X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e17d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b606ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25% of the train set is split as a validation set\n",
    "\n",
    "\n",
    "X_test = Test_Data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(Train_Data.loc[:, Train_Data.columns != \"Burn Rate\"],\n",
    "                                                    Train_Data.loc[:, Train_Data.columns == \"Burn Rate\"],\n",
    "                                                    test_size=0.25, \n",
    "                                                    random_state=42)\n",
    "\n",
    "print(\"Shape of the train set:\\nX_train:\", X_train.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"\\nShape of the validation set:\\nX_val:\", X_val.shape)\n",
    "print(\"y_val:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999aac8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = StandardScaler()\n",
    "normalize = MinMaxScaler((0, 1))\n",
    "\n",
    "# scaled set: mean=0, standard deviation=1\n",
    "X_train_std = scale.fit_transform(X_train)\n",
    "X_val_std = scale.fit_transform(X_val)\n",
    "X_test_std = scale.fit_transform(X_test)\n",
    "\n",
    "# normalized set: values are between [0, 1]\n",
    "X_train_norm = normalize.fit_transform(X_train)\n",
    "X_val_norm = normalize.fit_transform(X_val)\n",
    "X_test_norm = normalize.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff77234",
   "metadata": {},
   "source": [
    "# MODEL ENGINEERING "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8959d3",
   "metadata": {},
   "source": [
    "## Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc92e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3450d5",
   "metadata": {},
   "source": [
    "####  CREATING FUNCTION TO CAL PARAMETERS - r2_score AND RMSE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d796639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2 SCORE\n",
    "from sklearn.metrics import r2_score\n",
    "def pred_r2_score(y_train, train_pred, y_test, test_pred):\n",
    "    r2_train = r2_score(y_train, train_pred)\n",
    "    r2_test = r2_score(y_test, test_pred)\n",
    "    return r2_train, r2_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a765e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE(ROOT MEAN SQUARED ERROR)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def RMSE(y_train, train_pred, y_test, test_pred):\n",
    "    Train_error = mean_squared_error(y_train,train_pred)\n",
    "    Test_error = mean_squared_error(y_test,test_pred)\n",
    "    return Train_error**0.5, Test_error**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51fbe8d",
   "metadata": {},
   "source": [
    "#### CREATING LISTS FOR RMSE AND R2 SCORES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446b1580",
   "metadata": {},
   "outputs": [],
   "source": [
    "R2_Train=[]\n",
    "R2_Test=[]\n",
    "RMSE_Train=[]\n",
    "RMSE_Test=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad796845",
   "metadata": {},
   "source": [
    "### APPLYING LINEAR REGRESSION MODEL  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b6d367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "#fit the model\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "train_pred = lr_model.predict(X_train)\n",
    "test_pred = lr_model.predict(X_val)\n",
    "\n",
    "#R2 score and RMSE\n",
    "R2_Linear_Train,R2_Linear_Test = pred_r2_score(y_train, train_pred, y_val, test_pred)\n",
    "RMSE_Linear_Train,RMSE_Linear_Test = RMSE(y_train, train_pred, y_val, test_pred)\n",
    "\n",
    "#Print values\n",
    "print(\"R2 Score of Train Data: \",R2_Linear_Train)\n",
    "print(\"R2 Score of Train Data: \",R2_Linear_Test)\n",
    "print(\"RMSE value of Train Data: \",RMSE_Linear_Train)\n",
    "print(\"RMSE value of Train Data: \",RMSE_Linear_Test)\n",
    "\n",
    "# Append values to lists\n",
    "R2_Train.append(R2_Linear_Train)\n",
    "R2_Test.append(R2_Linear_Test)\n",
    "RMSE_Train.append(RMSE_Linear_Train)\n",
    "RMSE_Test.append(RMSE_Linear_Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397a0ead",
   "metadata": {},
   "source": [
    "## RIDGE  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dc208e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import  RidgeCV\n",
    "ridge_CV_model = RidgeCV(alphas=np.logspace(-8, 6, num=30, base=10.0), \n",
    "                        cv=10)\n",
    "#Ridge_CV = RidgeCV()\n",
    "ridge_CV = ridge_CV_model.fit(X_train, y_train)\n",
    "\n",
    "#Fit the model\n",
    "ridge_CV_score = ridge_CV.predict(X_train)\n",
    "ridge_CV_score2 = ridge_CV.predict(X_val)\n",
    "\n",
    "#R2 score and RMSE\n",
    "R2_Ridge_Train,R2_Ridge_Test = pred_r2_score(y_train,ridge_CV_score,y_val,ridge_CV_score2)\n",
    "RMSE_Ridge_Train,RMSE_Ridge_Test = RMSE(y_train,ridge_CV_score,y_val,ridge_CV_score2)\n",
    "\n",
    "#Print values\n",
    "print(\"R2 Score of Train Data: \",R2_Ridge_Train)\n",
    "print(\"R2 Score of Train Data: \",R2_Ridge_Test)\n",
    "print(\"RMSE value of Train Data: \",RMSE_Ridge_Train)\n",
    "print(\"RMSE value of Train Data: \",RMSE_Ridge_Test)\n",
    "\n",
    "# Append values to lists\n",
    "R2_Train.append(R2_Ridge_Train)\n",
    "R2_Test.append(R2_Ridge_Test)\n",
    "RMSE_Train.append(RMSE_Ridge_Train)\n",
    "RMSE_Test.append(RMSE_Ridge_Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de24bae",
   "metadata": {},
   "source": [
    "## RANDOM FOREST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6e5f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#Intialize the model\n",
    "RFR = RandomForestRegressor()\n",
    "\n",
    "#Fit the model\n",
    "RFR.fit(X_train, y_train)\n",
    "\n",
    "#Make Predictions\n",
    "train_pred_rf = RFR.predict(X_train)\n",
    "test_pred_rf = RFR.predict(X_val)\n",
    "\n",
    "#R2 Score and RMSE\n",
    "R2_Rf_Train,R2_Rf_Test = pred_r2_score(y_train,train_pred_rf,y_val,test_pred_rf)\n",
    "RMSE_Rf_Train,RMSE_Rf_Test = RMSE(y_train,train_pred_rf,y_val,test_pred_rf)\n",
    "\n",
    "#Print values\n",
    "print(\"R2 Score of Train Data: \",R2_Rf_Train)\n",
    "print(\"R2 Score of Train Data: \",R2_Rf_Test)\n",
    "print(\"RMSE value of Train Data: \",RMSE_Rf_Train)\n",
    "print(\"RMSE value of Train Data: \",RMSE_Rf_Test)\n",
    "\n",
    "# Append values to lists\n",
    "R2_Train.append(R2_Rf_Train)\n",
    "R2_Test.append(R2_Rf_Test)\n",
    "RMSE_Train.append(RMSE_Rf_Train)\n",
    "RMSE_Test.append(RMSE_Rf_Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33cf1b8",
   "metadata": {},
   "source": [
    "## Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6eba61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor as GBR\n",
    "#Intialize the model\n",
    "GBR = GBR()\n",
    "\n",
    "#Fit the model\n",
    "GBR.fit(X_train , y_train)\n",
    "\n",
    "#Make Predictions\n",
    "GBR_y_pred = GBR.predict(X_train)\n",
    "GBR_y_pred_val = GBR.predict(X_val)\n",
    "\n",
    "#R2 Score and RMSE\n",
    "R2_Grad_Train,R2_Grad_Test = pred_r2_score(y_train,GBR_y_pred,y_val,GBR_y_pred_val)\n",
    "RMSE_Grad_Train,RMSE_Grad_Test = RMSE(y_train,GBR_y_pred,y_val,GBR_y_pred_val)\n",
    "\n",
    "#Print values\n",
    "print(\"R2 Score of Train Data: \",R2_Grad_Train)\n",
    "print(\"R2 Score of Train Data: \",R2_Grad_Test)\n",
    "print(\"RMSE value of Train Data: \",RMSE_Grad_Train)\n",
    "print(\"RMSE value of Train Data: \",RMSE_Grad_Test)\n",
    "\n",
    "# Append values to lists\n",
    "R2_Train.append(R2_Grad_Train)\n",
    "R2_Test.append(R2_Grad_Test)\n",
    "RMSE_Train.append(RMSE_Grad_Train)\n",
    "RMSE_Test.append(RMSE_Grad_Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02663364",
   "metadata": {},
   "source": [
    "## ADA Boost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27607e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor as ADA\n",
    "#Intialize the model\n",
    "ADA = ADA()\n",
    "\n",
    "#Fit the model\n",
    "ADA.fit(X_train,y_train)\n",
    "\n",
    "#Make Predictions\n",
    "ADA_y_pred = ADA.predict(X_train)\n",
    "ADA_y_pred_val = ADA.predict(X_val)\n",
    "\n",
    "#R2 Score and RMSE\n",
    "R2_ADA_Train,R2_ADA_Test = pred_r2_score(y_train,ADA_y_pred,y_val,ADA_y_pred_val)\n",
    "RMSE_ADA_Train,RMSE_ADA_Test = RMSE(y_train,ADA_y_pred,y_val,ADA_y_pred_val)\n",
    "\n",
    "#Print values\n",
    "print(\"R2 Score of Train Data: \",R2_ADA_Train)\n",
    "print(\"R2 Score of Train Data: \",R2_ADA_Test)\n",
    "print(\"RMSE value of Train Data: \",RMSE_ADA_Train)\n",
    "print(\"RMSE value of Train Data: \",RMSE_ADA_Test)\n",
    "\n",
    "# Append values to lists\n",
    "R2_Train.append(R2_ADA_Train)\n",
    "R2_Test.append(R2_ADA_Test)\n",
    "RMSE_Train.append(RMSE_ADA_Train)\n",
    "RMSE_Test.append(RMSE_ADA_Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8574438c",
   "metadata": {},
   "source": [
    "## XGBOOST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527e2a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37074d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor as XGB\n",
    "\n",
    "# Initiate the model\n",
    "xg = XGB()\n",
    "\n",
    "# Fit the model\n",
    "xg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "xg_y_pr = xg.predict(X_train)\n",
    "xg_y_pred = xg.predict(X_val)\n",
    "\n",
    "#R2 Score and RMSE\n",
    "R2_XGB_Train,R2_XGB_Test = pred_r2_score(y_train,xg_y_pr,y_val,xg_y_pred)\n",
    "RMSE_XGB_Train,RMSE_XGB_Test = RMSE(y_train,xg_y_pr,y_val,xg_y_pred)\n",
    "\n",
    "#Print values\n",
    "print(\"R2 Score of Train Data: \",R2_XGB_Train)\n",
    "print(\"R2 Score of Train Data: \",R2_XGB_Test)\n",
    "print(\"RMSE value of Train Data: \",RMSE_XGB_Train)\n",
    "print(\"RMSE value of Train Data: \",RMSE_XGB_Test)\n",
    "\n",
    "# Append values to lists\n",
    "R2_Train.append(R2_XGB_Train)\n",
    "R2_Test.append(R2_XGB_Test)\n",
    "RMSE_Train.append(RMSE_XGB_Train)\n",
    "RMSE_Test.append(RMSE_XGB_Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245672b9",
   "metadata": {},
   "source": [
    "## CATBOOST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc15849",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install catboost\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ea7be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_model=CatBoostRegressor()\n",
    "cat_model.fit(X_train, y_train)\n",
    "\n",
    "#fit the model\n",
    "train_pred_cat = cat_model.predict(X_train)\n",
    "test_pred_cat = cat_model.predict(X_val)\n",
    "\n",
    "#R2 Score and RMSE\n",
    "R2_Cat_Train,R2_Cat_Test = pred_r2_score(y_train,train_pred_cat,y_val,test_pred_cat)\n",
    "RMSE_Cat_Train,RMSE_Cat_Test = RMSE(y_train,train_pred_cat,y_val,test_pred_cat)\n",
    "\n",
    "#Print values\n",
    "print(\"R2 Score of Train Data: \",R2_Cat_Train)\n",
    "print(\"R2 Score of Train Data: \",R2_Cat_Test)\n",
    "print(\"RMSE value of Train Data: \",RMSE_Cat_Train)\n",
    "print(\"RMSE value of Train Data: \",RMSE_Cat_Test)\n",
    "\n",
    "# Append values to lists\n",
    "R2_Train.append(R2_Cat_Train)\n",
    "R2_Test.append(R2_Cat_Test)\n",
    "RMSE_Train.append(RMSE_Cat_Train)\n",
    "RMSE_Test.append(RMSE_Cat_Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d84edb6",
   "metadata": {},
   "source": [
    "# PLOTTING GRAPH OF PARAMETERS TO FIND THE BEST FIT MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4105e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#R2_Train\n",
    "#R2_Test\n",
    "#RMSE_Train\n",
    "#RMSE_Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e715ef94",
   "metadata": {},
   "source": [
    "#### PLOT LINEPLOT OF TRAIN DATA PARAMETERS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadfab9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"Linear\",\"Ridge\",\"Random Forest\",\"Gradient Boost\",\"ADA Boost\",\"XGBoost\",\"Catboost\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff188b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "plt.plot(models,R2_Train)\n",
    "plt.plot(models,R2_Test,color='green')\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"R2 score\")\n",
    "plt.title(\"R2 SCORES FOR DIFFERENT MODELS\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e8f801",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "plt.plot(models,RMSE_Train,color='blue')\n",
    "plt.plot(models,RMSE_Test,color='orange')\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"RMSE value\")\n",
    "plt.title(\"RMSE VALUES FOR DIFFERENT MODELS\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bb2ba8",
   "metadata": {},
   "source": [
    "#### LOOKING AT THE ABOVE GRAPHS WE CONCLUDE THAT CATBOOST IS THE BEST FIT MODEL "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba4d453",
   "metadata": {},
   "source": [
    "## SAVING THE MODEL USING PICKLE FUNCTION  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d8e26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTING VALUE OF \n",
    "prediction = cat_model.predict(X_train.head(1))\n",
    "print(prediction*100)\n",
    "\n",
    "print(y_train.head(1)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5e3606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING PICKLE\n",
    "import pickle\n",
    "\n",
    "# SAVING MODEL \n",
    "\n",
    "pickle.dump(cat_model,open(\"cat_model_pickle.pkl\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa86acd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOADING MODEL    \n",
    "loaded_model= pickle.load(open(\"cat_model_pickle.pkl\",'rb'))\n",
    "loaded_model.predict(X_test)\n",
    "    #cat_model=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5b3145",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction_2 = cat_model.predict(X_train.head(1))\n",
    "#print(prediction_2*100)\n",
    "\n",
    "#print(y_train.head(1)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344b64b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
